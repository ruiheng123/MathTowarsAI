{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "from functools import wraps, partial\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import transforms as T\n",
    "\n",
    "# helper functions\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def default(val, default):\n",
    "    return val if exists(val) else default\n",
    "\n",
    "def singleton(cache_key):\n",
    "    def inner_fn(fn):\n",
    "        @wraps(fn)\n",
    "        def wrapper(self, *args, **kwargs):\n",
    "            instance = getattr(self, cache_key)\n",
    "            if instance is not None:\n",
    "                return instance\n",
    "\n",
    "            instance = fn(self, *args, **kwargs)\n",
    "            setattr(self, cache_key, instance)\n",
    "            return instance\n",
    "        return wrapper\n",
    "    return inner_fn\n",
    "\n",
    "def get_module_device(module):\n",
    "    return next(module.parameters()).device\n",
    "\n",
    "def set_requires_grad(model, val):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = val\n",
    "\n",
    "# loss function # (algorithm 1 in the paper)\n",
    "\n",
    "def loss_fn(\n",
    "    teacher_logits,\n",
    "    student_logits,\n",
    "    teacher_temp,\n",
    "    student_temp,\n",
    "    centers,\n",
    "    eps = 1e-20\n",
    "):\n",
    "    teacher_logits = teacher_logits.detach()\n",
    "    student_probs = (student_logits / student_temp).softmax(dim = -1)\n",
    "    teacher_probs = ((teacher_logits - centers) / teacher_temp).softmax(dim = -1)\n",
    "    return - (teacher_probs * torch.log(student_probs + eps)).sum(dim = -1).mean()\n",
    "\n",
    "# augmentation utils\n",
    "\n",
    "class RandomApply(nn.Module):\n",
    "    def __init__(self, fn, p):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if random.random() > self.p:\n",
    "            return x\n",
    "        return self.fn(x)\n",
    "\n",
    "# exponential moving average\n",
    "\n",
    "class EMA():\n",
    "    def __init__(self, beta):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "\n",
    "    def update_average(self, old, new):\n",
    "        if old is None:\n",
    "            return new\n",
    "        return old * self.beta + (1 - self.beta) * new\n",
    "\n",
    "def update_moving_average(ema_updater, ma_model, current_model):\n",
    "    for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n",
    "        old_weight, up_weight = ma_params.data, current_params.data\n",
    "        ma_params.data = ema_updater.update_average(old_weight, up_weight)\n",
    "\n",
    "# MLP class for projector and predictor\n",
    "\n",
    "class L2Norm(nn.Module):\n",
    "    def forward(self, x, eps = 1e-6):\n",
    "        norm = x.norm(dim = 1, keepdim = True).clamp(min = eps)\n",
    "        return x / norm\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim, dim_out, num_layers, hidden_size = 256):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "        dims = (dim, *((hidden_size,) * (num_layers - 1)))\n",
    "\n",
    "        for ind, (layer_dim_in, layer_dim_out) in enumerate(zip(dims[:-1], dims[1:])):\n",
    "            is_last = ind == (len(dims) - 1)\n",
    "\n",
    "            layers.extend([\n",
    "                nn.Linear(layer_dim_in, layer_dim_out),\n",
    "                nn.GELU() if not is_last else nn.Identity()\n",
    "            ])\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            *layers,\n",
    "            L2Norm(),\n",
    "            nn.Linear(hidden_size, dim_out)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# a wrapper class for the base neural network\n",
    "# will manage the interception of the hidden layer output\n",
    "# and pipe it into the projecter and predictor nets\n",
    "\n",
    "class NetWrapper(nn.Module):\n",
    "    def __init__(self, net, output_dim, projection_hidden_size, projection_num_layers, layer = -2):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "        self.layer = layer\n",
    "\n",
    "        self.projector = None\n",
    "        self.projection_hidden_size = projection_hidden_size\n",
    "        self.projection_num_layers = projection_num_layers\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.hidden = {}\n",
    "        self.hook_registered = False\n",
    "\n",
    "    def _find_layer(self):\n",
    "        if type(self.layer) == str:\n",
    "            modules = dict([*self.net.named_modules()])\n",
    "            return modules.get(self.layer, None)\n",
    "        elif type(self.layer) == int:\n",
    "            children = [*self.net.children()]\n",
    "            return children[self.layer]\n",
    "        return None\n",
    "\n",
    "    def _hook(self, _, input, output):\n",
    "        device = input[0].device\n",
    "        self.hidden[device] = output.flatten(1)\n",
    "\n",
    "    def _register_hook(self):\n",
    "        layer = self._find_layer()\n",
    "        assert layer is not None, f'hidden layer ({self.layer}) not found'\n",
    "        handle = layer.register_forward_hook(self._hook)\n",
    "        self.hook_registered = True\n",
    "\n",
    "    @singleton('projector')\n",
    "    def _get_projector(self, hidden):\n",
    "        _, dim = hidden.shape\n",
    "        projector = MLP(dim, self.output_dim, self.projection_num_layers, self.projection_hidden_size)\n",
    "        return projector.to(hidden)\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        if self.layer == -1:\n",
    "            return self.net(x)\n",
    "\n",
    "        if not self.hook_registered:\n",
    "            self._register_hook()\n",
    "\n",
    "        self.hidden.clear()\n",
    "        _ = self.net(x)\n",
    "        hidden = self.hidden[x.device]\n",
    "        self.hidden.clear()\n",
    "\n",
    "        assert hidden is not None, f'hidden layer {self.layer} never emitted an output'\n",
    "        return hidden\n",
    "\n",
    "    def forward(self, x, return_projection = True):\n",
    "        embed = self.get_embedding(x)\n",
    "        if not return_projection:\n",
    "            return embed\n",
    "\n",
    "        projector = self._get_projector(embed)\n",
    "        return projector(embed), embed\n",
    "\n",
    "# main class\n",
    "\n",
    "class Dino(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        net,\n",
    "        image_size,\n",
    "        hidden_layer = -2,\n",
    "        projection_hidden_size = 256,\n",
    "        num_classes_K = 65336,\n",
    "        projection_layers = 4,\n",
    "        student_temp = 0.9,\n",
    "        teacher_temp = 0.04,\n",
    "        local_upper_crop_scale = 0.4,\n",
    "        global_lower_crop_scale = 0.5,\n",
    "        moving_average_decay = 0.9,\n",
    "        center_moving_average_decay = 0.9,\n",
    "        augment_fn = None,\n",
    "        augment_fn2 = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "\n",
    "        # default BYOL augmentation\n",
    "\n",
    "        DEFAULT_AUG = torch.nn.Sequential(\n",
    "            RandomApply(\n",
    "                T.ColorJitter(0.8, 0.8, 0.8, 0.2),\n",
    "                p = 0.3\n",
    "            ),\n",
    "            T.RandomGrayscale(p=0.2),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            RandomApply(\n",
    "                T.GaussianBlur((3, 3), (1.0, 2.0)),\n",
    "                p = 0.2\n",
    "            ),\n",
    "            T.Normalize(\n",
    "                mean=torch.tensor([0.485, 0.456, 0.406]),\n",
    "                std=torch.tensor([0.229, 0.224, 0.225])),\n",
    "        )\n",
    "\n",
    "        self.augment1 = default(augment_fn, DEFAULT_AUG)\n",
    "        self.augment2 = default(augment_fn2, DEFAULT_AUG)\n",
    "\n",
    "        # local and global crops\n",
    "\n",
    "        self.local_crop = T.RandomResizedCrop((image_size, image_size), scale = (0.05, local_upper_crop_scale))\n",
    "        self.global_crop = T.RandomResizedCrop((image_size, image_size), scale = (global_lower_crop_scale, 1.))\n",
    "\n",
    "        self.student_encoder = NetWrapper(net, num_classes_K, projection_hidden_size, projection_layers, layer = hidden_layer)\n",
    "\n",
    "        self.teacher_encoder = None\n",
    "        self.teacher_ema_updater = EMA(moving_average_decay)\n",
    "\n",
    "        self.register_buffer('teacher_centers', torch.zeros(1, num_classes_K))\n",
    "        self.register_buffer('last_teacher_centers',  torch.zeros(1, num_classes_K))\n",
    "\n",
    "        self.teacher_centering_ema_updater = EMA(center_moving_average_decay)\n",
    "\n",
    "        self.student_temp = student_temp\n",
    "        self.teacher_temp = teacher_temp\n",
    "\n",
    "        # get device of network and make wrapper same device\n",
    "        device = get_module_device(net)\n",
    "        self.to(device)\n",
    "\n",
    "        # send a mock image tensor to instantiate singleton parameters\n",
    "        self.forward(torch.randn(2, 3, image_size, image_size, device=device))\n",
    "\n",
    "    @singleton('teacher_encoder')\n",
    "    def _get_teacher_encoder(self):\n",
    "        teacher_encoder = copy.deepcopy(self.student_encoder)\n",
    "        set_requires_grad(teacher_encoder, False)\n",
    "        return teacher_encoder\n",
    "\n",
    "    def reset_moving_average(self):\n",
    "        del self.teacher_encoder\n",
    "        self.teacher_encoder = None\n",
    "\n",
    "    def update_moving_average(self):\n",
    "        assert self.teacher_encoder is not None, 'target encoder has not been created yet'\n",
    "        update_moving_average(self.teacher_ema_updater, self.teacher_encoder, self.student_encoder)\n",
    "\n",
    "        new_teacher_centers = self.teacher_centering_ema_updater.update_average(self.teacher_centers, self.last_teacher_centers)\n",
    "        self.teacher_centers.copy_(new_teacher_centers)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        return_embedding = False,\n",
    "        return_projection = True,\n",
    "        student_temp = None,\n",
    "        teacher_temp = None\n",
    "    ):\n",
    "        if return_embedding:\n",
    "            return self.student_encoder(x, return_projection = return_projection)\n",
    "\n",
    "        image_one, image_two = self.augment1(x), self.augment2(x)\n",
    "\n",
    "        local_image_one, local_image_two   = self.local_crop(image_one),  self.local_crop(image_two)\n",
    "        global_image_one, global_image_two = self.global_crop(image_one), self.global_crop(image_two)\n",
    "\n",
    "        student_proj_one, _ = self.student_encoder(local_image_one)\n",
    "        student_proj_two, _ = self.student_encoder(local_image_two)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_encoder = self._get_teacher_encoder()\n",
    "            teacher_proj_one, _ = teacher_encoder(global_image_one)\n",
    "            teacher_proj_two, _ = teacher_encoder(global_image_two)\n",
    "\n",
    "        loss_fn_ = partial(\n",
    "            loss_fn,\n",
    "            student_temp = default(student_temp, self.student_temp),\n",
    "            teacher_temp = default(teacher_temp, self.teacher_temp),\n",
    "            centers = self.teacher_centers\n",
    "        )\n",
    "\n",
    "        teacher_logits_avg = torch.cat((teacher_proj_one, teacher_proj_two)).mean(dim = 0)\n",
    "        self.last_teacher_centers.copy_(teacher_logits_avg)\n",
    "\n",
    "        loss = (loss_fn_(teacher_proj_one, student_proj_two) + loss_fn_(teacher_proj_two, student_proj_one)) / 2\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [11:37<00:00,  6.97s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from vit_pytorch import ViT\n",
    "model = ViT(\n",
    "    image_size = 256,\n",
    "    patch_size = 32,\n",
    "    num_classes = 1000,\n",
    "    dim = 1024,\n",
    "    depth = 6,\n",
    "    heads = 8,\n",
    "    mlp_dim = 2048\n",
    ")\n",
    "\n",
    "learner = Dino(\n",
    "    model,\n",
    "    image_size = 256,\n",
    "    hidden_layer = 'to_latent',        # hidden layer name or index, from which to extract the embedding\n",
    "    projection_hidden_size = 256,      # projector network hidden dimension\n",
    "    projection_layers = 4,             # number of layers in projection network\n",
    "    num_classes_K = 65336,             # output logits dimensions (referenced as K in paper)\n",
    "    student_temp = 0.9,                # student temperature\n",
    "    teacher_temp = 0.04,               # teacher temperature, needs to be annealed from 0.04 to 0.07 over 30 epochs\n",
    "    local_upper_crop_scale = 0.4,      # upper bound for local crop - 0.4 was recommended in the paper \n",
    "    global_lower_crop_scale = 0.5,     # lower bound for global crop - 0.5 was recommended in the paper\n",
    "    moving_average_decay = 0.9,        # moving average of encoder - paper showed anywhere from 0.9 to 0.999 was ok\n",
    "    center_moving_average_decay = 0.9, # moving average of teacher centers - paper showed anywhere from 0.9 to 0.999 was ok\n",
    ")\n",
    "\n",
    "opt = torch.optim.Adam(learner.parameters(), lr = 3e-4)\n",
    "\n",
    "def sample_unlabelled_images():\n",
    "    return torch.randn(20, 3, 256, 256)\n",
    "import tqdm\n",
    "for _ in tqdm.tqdm(range(100)):\n",
    "    images = sample_unlabelled_images()\n",
    "    loss = learner(images)\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    learner.update_moving_average() # update moving average of teacher encoder and teacher centers\n",
    "\n",
    "# save your improved network\n",
    "torch.save(model.state_dict(), './pretrained-net.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
